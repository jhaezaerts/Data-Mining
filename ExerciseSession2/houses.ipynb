{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Mining [H02C6a] - Spring 2021\n",
    "\n",
    "# Predicting House Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = '../img/house.jpg' align = 'right' width = 40%>\n",
    "\n",
    "In this exercise, we will try to find out what influences the prices of residential homes rented in Ames, Iowa. The dataset is available on [Kaggle](https://www.kaggle.com/c/house-prices-advanced-regression-techniques) and consists of 79 features, each representing some aspect that could possibly be related to a house's price (a [list of all features](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data) can be found in the data description on Kaggle). \n",
    "\n",
    "The goal of this exercise is to evaluate the performance of several linear regression methods on this dataset. More specifically, we'll compare ordinary least squares linear regression with its regularized versions (Lasso and Ridge)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by importing the required packages. We'll use ``scikit-learn`` in this session. You can install it using the following line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "%matplotlib inline\n",
    "# To suppress scikit-learn warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the house prices dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../datasets/houses.csv')\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When looking at the dataset, it becomes immediately clear that there are some columns with missing values that must be replaced by some value. \n",
    "\n",
    "Note that it does not always make sense to fill in the missing value with mean/median/most common value of the corresponding feature. \n",
    "\n",
    "For this dataset, we will use the solution from the [notebook](https://www.kaggle.com/juliencs/a-study-on-regression-applied-to-the-ames-dataset) that already did a more clever missing value imputation based on additional information about the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alley : data description says NA means \"no alley access\"\n",
    "data.loc[:, \"Alley\"] = data.loc[:, \"Alley\"].fillna(\"None\")\n",
    "# BedroomAbvGr: NA most likely means 0\n",
    "data.loc[:, \"BedroomAbvGr\"] = data.loc[:, \"BedroomAbvGr\"].fillna(0)\n",
    "# BsmtQual etc: data description says NA for basement features is \"no basement\"\n",
    "data.loc[:, \"BsmtQual\"] = data.loc[:, \"BsmtQual\"].fillna(\"No\")\n",
    "data.loc[:, \"BsmtCond\"] = data.loc[:, \"BsmtCond\"].fillna(\"No\")\n",
    "data.loc[:, \"BsmtExposure\"] = data.loc[:, \"BsmtExposure\"].fillna(\"No\")\n",
    "data.loc[:, \"BsmtFinType1\"] = data.loc[:, \"BsmtFinType1\"].fillna(\"No\")\n",
    "data.loc[:, \"BsmtFinType2\"] = data.loc[:, \"BsmtFinType2\"].fillna(\"No\")\n",
    "data.loc[:, \"BsmtFullBath\"] = data.loc[:, \"BsmtFullBath\"].fillna(0)\n",
    "data.loc[:, \"BsmtHalfBath\"] = data.loc[:, \"BsmtHalfBath\"].fillna(0)\n",
    "data.loc[:, \"BsmtUnfSF\"] = data.loc[:, \"BsmtUnfSF\"].fillna(0)\n",
    "# CentralAir: NA most likely means No\n",
    "data.loc[:, \"CentralAir\"] = data.loc[:, \"CentralAir\"].fillna(\"N\")\n",
    "# Condition: NA most likely means Normal\n",
    "data.loc[:, \"Condition1\"] = data.loc[:, \"Condition1\"].fillna(\"Norm\")\n",
    "data.loc[:, \"Condition2\"] = data.loc[:, \"Condition2\"].fillna(\"Norm\")\n",
    "# EnclosedPorch: NA most likely means no enclosed porch\n",
    "data.loc[:, \"EnclosedPorch\"] = data.loc[:, \"EnclosedPorch\"].fillna(0)\n",
    "# External stuff: NA most likely means average\n",
    "data.loc[:, \"ExterCond\"] = data.loc[:, \"ExterCond\"].fillna(\"TA\")\n",
    "data.loc[:, \"ExterQual\"] = data.loc[:, \"ExterQual\"].fillna(\"TA\")\n",
    "# Fence: data description says NA means \"no fence\"\n",
    "data.loc[:, \"Fence\"] = data.loc[:, \"Fence\"].fillna(\"No\")\n",
    "# FireplaceQu: data description says NA means \"no fireplace\"\n",
    "data.loc[:, \"FireplaceQu\"] = data.loc[:, \"FireplaceQu\"].fillna(\"No\")\n",
    "data.loc[:, \"Fireplaces\"] = data.loc[:, \"Fireplaces\"].fillna(0)\n",
    "# Functional: data description says NA means typical\n",
    "data.loc[:, \"Functional\"] = data.loc[:, \"Functional\"].fillna(\"Typ\")\n",
    "# GarageType etc: data description says NA for garage features is \"no garage\"\n",
    "data.loc[:, \"GarageType\"] = data.loc[:, \"GarageType\"].fillna(\"No\")\n",
    "data.loc[:, \"GarageFinish\"] = data.loc[:, \"GarageFinish\"].fillna(\"No\")\n",
    "data.loc[:, \"GarageQual\"] = data.loc[:, \"GarageQual\"].fillna(\"No\")\n",
    "data.loc[:, \"GarageCond\"] = data.loc[:, \"GarageCond\"].fillna(\"No\")\n",
    "data.loc[:, \"GarageArea\"] = data.loc[:, \"GarageArea\"].fillna(0)\n",
    "data.loc[:, \"GarageCars\"] = data.loc[:, \"GarageCars\"].fillna(0)\n",
    "# HalfBath: NA most likely means no half baths above grade\n",
    "data.loc[:, \"HalfBath\"] = data.loc[:, \"HalfBath\"].fillna(0)\n",
    "# HeatingQC: NA most likely means typical\n",
    "data.loc[:, \"HeatingQC\"] = data.loc[:, \"HeatingQC\"].fillna(\"TA\")\n",
    "# KitchenAbvGr: NA most likely means 0\n",
    "data.loc[:, \"KitchenAbvGr\"] = data.loc[:, \"KitchenAbvGr\"].fillna(0)\n",
    "# KitchenQual: NA most likely means typical\n",
    "data.loc[:, \"KitchenQual\"] = data.loc[:, \"KitchenQual\"].fillna(\"TA\")\n",
    "# LotFrontage: NA most likely means no lot frontage\n",
    "data.loc[:, \"LotFrontage\"] = data.loc[:, \"LotFrontage\"].fillna(0)\n",
    "# LotShape: NA most likely means regular\n",
    "data.loc[:, \"LotShape\"] = data.loc[:, \"LotShape\"].fillna(\"Reg\")\n",
    "# MasVnrType: NA most likely means no veneer\n",
    "data.loc[:, \"MasVnrType\"] = data.loc[:, \"MasVnrType\"].fillna(\"None\")\n",
    "data.loc[:, \"MasVnrArea\"] = data.loc[:, \"MasVnrArea\"].fillna(0)\n",
    "# MiscFeature: data description says NA means \"no misc feature\"\n",
    "data.loc[:, \"MiscFeature\"] = data.loc[:, \"MiscFeature\"].fillna(\"No\")\n",
    "data.loc[:, \"MiscVal\"] = data.loc[:, \"MiscVal\"].fillna(0)\n",
    "# OpenPorchSF: NA most likely means no open porch\n",
    "data.loc[:, \"OpenPorchSF\"] = data.loc[:, \"OpenPorchSF\"].fillna(0)\n",
    "# PavedDrive: NA most likely means not paved\n",
    "data.loc[:, \"PavedDrive\"] = data.loc[:, \"PavedDrive\"].fillna(\"N\")\n",
    "# PoolQC: data description says NA means \"no pool\"\n",
    "data.loc[:, \"PoolQC\"] = data.loc[:, \"PoolQC\"].fillna(\"No\")\n",
    "data.loc[:, \"PoolArea\"] = data.loc[:, \"PoolArea\"].fillna(0)\n",
    "# SaleCondition: NA most likely means normal sale\n",
    "data.loc[:, \"SaleCondition\"] = data.loc[:, \"SaleCondition\"].fillna(\"Normal\")\n",
    "# ScreenPorch: NA most likely means no screen porch\n",
    "data.loc[:, \"ScreenPorch\"] = data.loc[:, \"ScreenPorch\"].fillna(0)\n",
    "# TotRmsAbvGrd: NA most likely means 0\n",
    "data.loc[:, \"TotRmsAbvGrd\"] = data.loc[:, \"TotRmsAbvGrd\"].fillna(0)\n",
    "# Utilities: NA most likely means all public utilities\n",
    "data.loc[:, \"Utilities\"] = data.loc[:, \"Utilities\"].fillna(\"AllPub\")\n",
    "# WoodDeckSF: NA most likely means no wood deck\n",
    "data.loc[:, \"WoodDeckSF\"] = data.loc[:, \"WoodDeckSF\"].fillna(0)\n",
    "\n",
    "# Handle remaining missing values for numerical features by using median as replacement\n",
    "data= data.fillna(data.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the Id column\n",
    "data.drop(\"Id\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression methods require the input data to be numerical. However, this is not the case for the dataset.\n",
    "\n",
    "Let's see which attributes are numeric and which attributes are categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = data.select_dtypes(exclude = [\"object\"]).columns.drop(\"SalePrice\")\n",
    "data_num = data[num]\n",
    "\n",
    "data_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = data.select_dtypes(include = [\"object\"]).columns\n",
    "data_cat = data[cat]\n",
    "\n",
    "data_cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color = 'red'>Question 1</font> Replace the categorical attributes by numerical attributes and store them again in the `data_cat` dataframe.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: look for \"one hot encoding\" in the `pandas` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we concatenate `data_num` and `data_cat` to create a dataframe `X` with the ready-to-use input data. We also create a series `y` with the target data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([data_num, data_cat], axis = 1)\n",
    "y = data['SalePrice']\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then split the dataset in training and test data: a separate test set is needed to evaluate the different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a last step before we start comparing different regression methods, we standardize the numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train.loc[:,num] = scaler.fit_transform(X_train.loc[:,num])\n",
    "X_test.loc[:,num] = scaler.transform(X_test.loc[:,num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordinary least squares linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model you will evaluate is a least squares linear regression model.\n",
    "\n",
    "We'll use the root mean squared error (RMSE) as the evaluation metric, which is defined as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return math.sqrt(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color = 'red'>Question 2</font> Train a linear model for `X_train` and evaluate its RMSE on `X_test`.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: you can use the <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\">`LinearRegression`</a> class of scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularized least squares linear regression\n",
    "\n",
    "A common problem with least squares linear regression models is that their accuracy is heavily influenced by [collinearity](https://en.wikipedia.org/wiki/Collinearity) and noise in the input features.\n",
    "\n",
    "To avoid this, we can use regularization techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2-regularization (Ridge regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Ridge regression](https://en.wikipedia.org/wiki/Tikhonov_regularization), also known as Tikhonov regularization and weight decay, is arguably the most commonly used method of regularization of ill-posed problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color = 'red'>Question 3</font> Train an L2-regularized linear model with default parameter settings on the training set and evaluate the RMSE of the obtained model on the training set.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: you can use the <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html\">`Ridge`</a> class of scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color = 'red'>Question 4</font> Try fitting the model with different values of the regularization parameter `alpha`. Plot Ridge coefficients as a function of `alpha`. Discuss what you see.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color = 'red'>Question 5</font> Now tune the `alpha` parameter and re-evaluate the `Ridge` regressor with the best value that you found.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: you can use the <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html\">`RidgeCV`</a> class of scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1-regularization (Lasso regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=https://en.wikipedia.org/wiki/Lasso_(statistics)>Lasso</a> (stands for Least Absolute Shrinkage and Selection Operator) is a regression analysis method that performs both variable selection and regularization in order to enhance the prediction accuracy and interpretability of the statistical model it produces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color = 'red'>Question 6</font> Train an L1-regularized linear model with default parameter settings on the training set and evaluate the RMSE of the obtained model on the test set.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: you can use the <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html\">`Lasso`</a> class of scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at the scikit-learn documentation, you will notice that `Lasso` has a parameter `alpha` which is the regularization constant for the L1-regularizer. In order to achieve a better accuracy, this parameter should be tuned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color = 'red'>Question 7</font> Now tune the `alpha` parameter and re-evaluate the `Lasso` regressor with the best value that you found.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: you can use the <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html\">`LassoCV`</a> class of scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color = 'red'>Question 8</font> Plot the number of non-zero coefficients as a function of `alpha` and discuss what you see.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
