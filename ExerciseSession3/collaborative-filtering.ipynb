{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommending movies using collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T19:41:48.346620Z",
     "start_time": "2020-03-24T19:41:47.795318Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build a recommender system, we need data to learn from. Specifically, we need the a dataset of **ratings** that different **users** assigend to different **items**, i.e., the movies. Let's start by loading the data and look at the first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T19:41:49.210677Z",
     "start_time": "2020-03-24T19:41:49.138507Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating\n",
       "0      196      242       3\n",
       "1      186      302       3\n",
       "2       22      377       1\n",
       "3      244       51       2\n",
       "4      166      346       1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.read_csv(\n",
    "    '../datasets/u.data',\n",
    "    delimiter='\\t',\n",
    "    header=None,\n",
    "    names=['user_id', 'item_id', 'rating', 'timestamp']\n",
    ") \n",
    "\n",
    "# We don't need the column timestamp, so we drop it\n",
    "ratings.drop('timestamp', axis=1 , inplace=True)\n",
    "\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.1: Similarity-based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1:** Implement the similarity-based algorithm given by the formulas of exercise 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2:** Let's now use the similarity function to find similar users. Given a user `u`, find the\n",
    "- user that is the most similar (positively correlated) to `u`;\n",
    "- user that is the least similar (negatively correlated) to `u`;\n",
    "- user that is weakly correlated to `u`.\n",
    "\n",
    "What can you say about the influence that these three users will have on the ratings of user `u`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User positively correlated: user Ellipsis with similarity = Ellipsis\n",
      "User negatively correlated: user Ellipsis with similarity = Ellipsis\n",
      "User weakly correlated: user Ellipsis with similarity = Ellipsis\n"
     ]
    }
   ],
   "source": [
    "u = 1\n",
    "...\n",
    "\n",
    "print('User positively correlated: user', ..., 'with similarity =', ...)\n",
    "print('User negatively correlated: user', ..., 'with similarity =', ...)\n",
    "print('User weakly correlated: user', ..., 'with similarity =', ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T20:25:28.779063Z",
     "start_time": "2020-03-24T20:25:28.774304Z"
    }
   },
   "source": [
    "**Question 3:** Use your implementation to predict an unknown rating of the dataset. What is the run time of your implementation? Can you think of ways to speed it up?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T19:54:12.638063Z",
     "start_time": "2020-03-24T19:54:11.923327Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.2: Model-based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make our life easier, we will now use the [Surprise](https://surprise.readthedocs.io) Python package which implements a variety of collaborative filtering algorithms. To install this package, simply run `pip install surprise` or use conda if you use Windows: open anaconda navigator, go to environments, click on the arrow next to the base (root) environment, click \"open terminal\" and run the following command: `conda install -y -c conda-forge scikit-surprise`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T20:17:40.110191Z",
     "start_time": "2020-03-24T20:17:39.972036Z"
    }
   },
   "outputs": [],
   "source": [
    "import surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to convert our dataset to a format where the rows represent users and the columns represent the movies. The value at each cell is the rating for corresponding user and movie, or zero if the user did not rate the movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T20:22:34.526564Z",
     "start_time": "2020-03-24T20:22:34.295657Z"
    }
   },
   "outputs": [],
   "source": [
    "from surprise.dataset import Dataset, Reader\n",
    "dataset = Dataset.load_from_df(ratings, reader=Reader(rating_scale=(1, 5)))\n",
    "X = dataset.build_full_trainset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4:** Now use the non-negative matrix factorization implementation of this package to predict the rating for a given user and movie.\n",
    "\n",
    "Hint: you'll need the [surprise.prediction_algorithms.matrix_factorization.NMF](https://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.NMF) class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T20:29:03.084232Z",
     "start_time": "2020-03-24T20:28:55.536552Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5:** What is the effect of the number of latent factors? Is there an optimal number of factors?\n",
    "\n",
    "Hint: the [surprise.model_selection.search.GridSearchCV](https://surprise.readthedocs.io/en/stable/model_selection.html#surprise.model_selection.search.GridSearchCV) makes it easy to compare different parameter settings (note that GridSearchCV.fit expects a Dataset object instead of a Trainset object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T21:05:52.161305Z",
     "start_time": "2020-03-24T21:05:51.790956Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
